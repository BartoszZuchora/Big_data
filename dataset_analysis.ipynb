{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TMDB 10000 Movies (2022) — EDA + wizualizacje (pomocnicze)\n",
        "\n",
        "**Uwaga dot. wymagań projektu:**\n",
        "- Ten notebook służy do **EDA, kontroli jakości danych i wizualizacji**.\n",
        "- **Główny trening modeli** oraz tuning hiperparametrów realizowany jest w **Apache Spark / Spark MLlib** (`tmdb_spark_ml.py`).\n",
        "- **Streaming + Kafka + Spark Structured Streaming** realizuje `front_app.py` + `stream_predict.py`.\n",
        "\n",
        "## Cel notebooka\n",
        "- sprawdzić strukturę CSV,\n",
        "- ocenić braki, typy danych, statystyki,\n",
        "- wykonać podstawowe wykresy,\n",
        "- zbudować *lekki* model porównawczy (scikit-learn) jako sanity-check.\n",
        "\n",
        "## Definicja sukcesu (spójna z pipeline Spark)\n",
        "- **SUKCES / hit**: `vote_average >= 7.0`\n",
        "- **NIE-SUKCES**: `vote_average < 7.0`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Jeśli uruchamiasz lokalnie: upewnij się, że masz pakiety.\n",
        "# Jeśli na Colab: odkomentuj instalację.\n",
        "\n",
        "!pip -q install pandas numpy matplotlib seaborn scikit-learn\n",
        "\n",
        "import os\n",
        "import re\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    ConfusionMatrixDisplay,\n",
        "    roc_auc_score,\n",
        ")\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "pd.set_option(\"display.max_columns\", 200)\n",
        "pd.set_option(\"display.width\", 140)\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "LABEL_THRESHOLD = 7.0  # spójnie z Spark MLlib\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Wczytanie danych\n",
        "\n",
        "Dataset: CSV (snapshot). W projekcie Big Data:\n",
        "- **Batch**: Spark wczytuje CSV i buduje modele (MLlib)\n",
        "- **Streaming**: Producer symuluje zdarzenia w JSON (Kafka)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "DATA_PATH = \"./data/tmdb_10000_movies.csv\"  # <- ustaw prawidłową ścieżkę\n",
        "assert os.path.exists(DATA_PATH), f\"Nie znaleziono pliku: {DATA_PATH}\"\n",
        "\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "df.head()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Shape:\", df.shape)\n",
        "df.info()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Szybka kontrola jakości\n",
        "- duplikaty\n",
        "- braki danych\n",
        "- wstępny przegląd rozkładów\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "n_duplicates = df.duplicated().sum()\n",
        "print(\"Liczba duplikatów wierszy:\", n_duplicates)\n",
        "\n",
        "missing = df.isna().mean().sort_values(ascending=False)\n",
        "display(missing.head(20).to_frame(\"missing_rate\"))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Automatyczna analiza kolumn (dtype, braki, unikalne, statystyki)\n",
        "\n",
        "Dla każdej kolumny raportujemy:\n",
        "- dtype\n",
        "- liczba braków i % braków\n",
        "- liczba unikalnych wartości\n",
        "- jeśli numeryczna: min/max/std/median/mean\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def try_parse_numeric(series: pd.Series) -> pd.Series:\n",
        "    \"\"\"Próba konwersji string->numeric (usuwa $, przecinki, spacje).\"\"\"\n",
        "    if series.dtype != \"object\":\n",
        "        return series\n",
        "\n",
        "    s = series.astype(str)\n",
        "    s = s.replace({\"None\": np.nan, \"nan\": np.nan, \"NaN\": np.nan, \"NULL\": np.nan, \"null\": np.nan})\n",
        "    s = s.str.replace(r\"[\\$,]\", \"\", regex=True).str.strip()\n",
        "    numeric = pd.to_numeric(s, errors=\"coerce\")\n",
        "\n",
        "    non_na_original = series.notna().sum()\n",
        "    non_na_numeric = numeric.notna().sum()\n",
        "    if non_na_original == 0:\n",
        "        return series\n",
        "    if non_na_numeric / non_na_original >= 0.85:\n",
        "        return numeric\n",
        "    return series\n",
        "\n",
        "\n",
        "df2 = df.copy()\n",
        "for c in df2.columns:\n",
        "    df2[c] = try_parse_numeric(df2[c])\n",
        "\n",
        "\n",
        "def column_report(frame: pd.DataFrame) -> pd.DataFrame:\n",
        "    rows = []\n",
        "    for col in frame.columns:\n",
        "        s = frame[col]\n",
        "        n = len(s)\n",
        "        n_missing = int(s.isna().sum())\n",
        "        missing_rate = n_missing / n if n else np.nan\n",
        "        nunique = int(s.nunique(dropna=True))\n",
        "        dtype = str(s.dtype)\n",
        "\n",
        "        stats = {\"min\": np.nan, \"max\": np.nan, \"std\": np.nan, \"median\": np.nan, \"mean\": np.nan}\n",
        "        if pd.api.types.is_numeric_dtype(s):\n",
        "            stats[\"min\"] = float(np.nanmin(s.values)) if s.notna().any() else np.nan\n",
        "            stats[\"max\"] = float(np.nanmax(s.values)) if s.notna().any() else np.nan\n",
        "            stats[\"std\"] = float(np.nanstd(s.values, ddof=1)) if s.notna().sum() > 1 else np.nan\n",
        "            stats[\"median\"] = float(np.nanmedian(s.values)) if s.notna().any() else np.nan\n",
        "            stats[\"mean\"] = float(np.nanmean(s.values)) if s.notna().any() else np.nan\n",
        "\n",
        "        rows.append({\n",
        "            \"column\": col,\n",
        "            \"dtype\": dtype,\n",
        "            \"missing_count\": n_missing,\n",
        "            \"missing_rate\": missing_rate,\n",
        "            \"nunique\": nunique,\n",
        "            **stats,\n",
        "        })\n",
        "    return (\n",
        "        pd.DataFrame(rows)\n",
        "        .sort_values([\"missing_rate\", \"nunique\"], ascending=[False, False])\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "\n",
        "\n",
        "report = column_report(df2)\n",
        "display(report)\n",
        "\n",
        "out_report_path = os.path.join(os.path.dirname(DATA_PATH), \"column_report.csv\")\n",
        "report.to_csv(out_report_path, index=False)\n",
        "print(\"Zapisano raport:\", out_report_path)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Wizualizacje: rozkłady i korelacje (numeryczne)\n",
        "\n",
        "Wybieramy kilka numerycznych kolumn o największej wariancji i pokazujemy histogramy.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "num_cols = [c for c in df2.columns if pd.api.types.is_numeric_dtype(df2[c])]\n",
        "print(\"Liczba kolumn numerycznych:\", len(num_cols))\n",
        "\n",
        "if len(num_cols) > 0:\n",
        "    variances = df2[num_cols].var(numeric_only=True).sort_values(ascending=False)\n",
        "    top = variances.head(8).index.tolist()\n",
        "    display(variances.head(15).to_frame(\"variance\"))\n",
        "\n",
        "    fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(18, 8))\n",
        "    axes = axes.flatten()\n",
        "    for ax, col in zip(axes, top):\n",
        "        sns.histplot(df2[col], kde=False, ax=ax, bins=40)\n",
        "        ax.set_title(col)\n",
        "    for ax in axes[len(top):]:\n",
        "        ax.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Brak kolumn numerycznych do pokazania.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if len(num_cols) >= 2:\n",
        "    corr = df2[num_cols].corr(numeric_only=True)\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(corr, cmap=\"coolwarm\", center=0)\n",
        "    plt.title(\"Korelacje (kolumny numeryczne)\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Za mało kolumn numerycznych do korelacji.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Target (etykieta) — SPÓJNY z projektem Spark\n",
        "\n",
        "Definiujemy `target_hit`:\n",
        "- `target_hit = 1` jeśli `vote_average >= 7.0`\n",
        "- `target_hit = 0` w przeciwnym wypadku\n",
        "\n",
        "To jest zgodne z `tmdb_spark_ml.py`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "assert \"vote_average\" in df2.columns, \"Brak kolumny vote_average w CSV\"\n",
        "\n",
        "# upewnij się, że vote_average jest numeryczne\n",
        "df2[\"vote_average\"] = pd.to_numeric(df2[\"vote_average\"], errors=\"coerce\")\n",
        "\n",
        "df2 = df2[df2[\"vote_average\"].notna()].copy()\n",
        "df2[\"target_hit\"] = (df2[\"vote_average\"] >= LABEL_THRESHOLD).astype(int)\n",
        "\n",
        "print(\"Próg vote_average:\", LABEL_THRESHOLD)\n",
        "df2[\"target_hit\"].value_counts(normalize=True).rename(\"share\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Feature engineering (baseline)\n",
        "\n",
        "Zasady:\n",
        "- usuwamy `vote_average` (bo to źródło label → leakage),\n",
        "- usuwamy identyfikatory i bardzo długie teksty w baseline,\n",
        "- model porównawczy ma charakter pomocniczy.\n",
        "\n",
        "W produkcyjnym pipeline (Spark) cechy są budowane w `tmdb_spark_ml.py`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "target_col = \"target_hit\"\n",
        "\n",
        "drop_cols = {target_col, \"vote_average\"}  # leakage\n",
        "\n",
        "for c in [\"id\", \"imdb_id\", \"tmdb_id\", \"title\", \"original_title\", \"poster_path\", \"backdrop_path\", \"overview\"]:\n",
        "    if c in df2.columns:\n",
        "        drop_cols.add(c)\n",
        "\n",
        "# Heurystyka: bardzo długi tekst -> drop w baseline\n",
        "for c in df2.columns:\n",
        "    if df2[c].dtype == \"object\":\n",
        "        avg_len = df2[c].dropna().astype(str).str.len().mean() if df2[c].notna().any() else 0\n",
        "        if avg_len and avg_len > 80:\n",
        "            drop_cols.add(c)\n",
        "\n",
        "print(\"Kolumny odrzucone (baseline):\")\n",
        "print(sorted(drop_cols))\n",
        "\n",
        "X = df2.drop(columns=[c for c in drop_cols if c in df2.columns])\n",
        "y = df2[target_col].astype(int)\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "display(y.value_counts().to_frame(\"count\"))\n",
        "\n",
        "num_features = [c for c in X.columns if pd.api.types.is_numeric_dtype(X[c])]\n",
        "cat_features = [c for c in X.columns if X[c].dtype == \"object\"]\n",
        "\n",
        "print(\"Num features:\", len(num_features))\n",
        "print(\"Cat features:\", len(cat_features))\n",
        "display(pd.DataFrame({\"num\": num_features}).head(20))\n",
        "display(pd.DataFrame({\"cat\": cat_features}).head(20))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Model porównawczy (scikit-learn) + macierz pomyłek\n",
        "\n",
        "**To jest tylko sanity-check.**\n",
        "Ocena i tuning docelowych modeli odbywa się w Spark MLlib.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=RANDOM_STATE,\n",
        "    stratify=y,\n",
        ")\n",
        "\n",
        "numeric_transformer = Pipeline(\n",
        "    steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    ]\n",
        ")\n",
        "\n",
        "categorical_transformer = Pipeline(\n",
        "    steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", min_frequency=10)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, num_features),\n",
        "        (\"cat\", categorical_transformer, cat_features),\n",
        "    ]\n",
        ")\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "model = Pipeline(steps=[(\"preprocess\", preprocess), (\"clf\", clf)])\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot(values_format=\"d\", cmap=\"Blues\", colorbar=False)\n",
        "for t in disp.text_.ravel():\n",
        "    t.set_color(\"black\")\n",
        "    t.set_fontsize(12)\n",
        "\n",
        "plt.title(\"Macierz pomyłek (sanity-check)\", color=\"black\")\n",
        "plt.xticks(color=\"black\")\n",
        "plt.yticks(color=\"black\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ROC-AUC (jeśli możliwe)\n",
        "if hasattr(model.named_steps[\"clf\"], \"predict_proba\"):\n",
        "    y_proba = model.predict_proba(X_test)[:, 1]\n",
        "    auc = roc_auc_score(y_test, y_proba)\n",
        "    print(\"ROC-AUC:\", round(auc, 4))"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
